{
  "django__django-16631": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-16631",
    "model_patch": ""
  },
  "sympy__sympy-24213": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sympy__sympy-24213",
    "model_patch": ""
  },
  "sphinx-doc__sphinx-7590": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-7590",
    "model_patch": "*** Begin Patch\n*** Update File: sphinx/domains/cpp.py\n@@\n class ASTLiteral(ASTExpression):\n     pass\n+\n+\n+class ASTUserDefinedLiteral(ASTLiteral):\n+    def __init__(self, literal: ASTLiteral, identifier: ASTIdentifier) -> None:\n+        self.literal = literal\n+        self.identifier = identifier\n+\n+    def _stringify(self, transform: StringifyTransform) -> str:\n+        # No space between literal and suffix\n+        return transform(self.literal) + transform(self.identifier)\n+\n+    def get_id(self, version: int) -> str:\n+        # Create a combined id. Use a 'li' like operator-literal as separator.\n+        # This is a pragmatic approach so ids are stable-ish and unique.\n+        return self.literal.get_id(version) + 'li' + self.identifier.get_id(version)\n+\n+    def describe_signature(self, signode: TextElement, mode: str,\n+                           env: \"BuildEnvironment\", symbol: \"Symbol\") -> None:\n+        verify_description_mode(mode)\n+        # display literal followed immediately by suffix\n+        self.literal.describe_signature(signode, mode, env, symbol)\n+        # Identifier should appear without space\n+        # For identifiers we want the plain text representation\n+        signode += nodes.Text(str(self.identifier))\n*** End Patch\n*** End Patch\n\nNo changes detected to generate a patch."
  },
  "django__django-10973": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-10973",
    "model_patch": "diff --git a/django/db/backends/postgresql/client.py b/django/db/backends/postgresql/client.py\nindex 7fca6eff30..a1724dd48f 100644\n--- a/django/db/backends/postgresql/client.py\n+++ b/django/db/backends/postgresql/client.py\n@@ -2,17 +2,9 @@ import os\n import signal\n import subprocess\n \n-from django.core.files.temp import NamedTemporaryFile\n from django.db.backends.base.client import BaseDatabaseClient\n \n \n-def _escape_pgpass(txt):\n-    \"\"\"\n-    Escape a fragment of a PostgreSQL .pgpass file.\n-    \"\"\"\n-    return txt.replace('\\\\', '\\\\\\\\').replace(':', '\\\\:')\n-\n-\n class DatabaseClient(BaseDatabaseClient):\n     executable_name = 'psql'\n \n@@ -34,38 +26,24 @@ class DatabaseClient(BaseDatabaseClient):\n             args += ['-p', str(port)]\n         args += [dbname]\n \n-        temp_pgpass = None\n         sigint_handler = signal.getsignal(signal.SIGINT)\n         try:\n+            env = os.environ.copy()\n             if passwd:\n-                # Create temporary .pgpass file.\n-                temp_pgpass = NamedTemporaryFile(mode='w+')\n+                # Set PGPASSWORD in the child process environment to avoid\n+                # creating a temporary .pgpass file. If the current locale\n+                # can't encode the password, let the user input the password\n+                # manually.\n                 try:\n-                    print(\n-                        _escape_pgpass(host) or '*',\n-                        str(port) or '*',\n-                        _escape_pgpass(dbname) or '*',\n-                        _escape_pgpass(user) or '*',\n-                        _escape_pgpass(passwd),\n-                        file=temp_pgpass,\n-                        sep=':',\n-                        flush=True,\n-                    )\n-                    os.environ['PGPASSFILE'] = temp_pgpass.name\n+                    env['PGPASSWORD'] = passwd\n                 except UnicodeEncodeError:\n-                    # If the current locale can't encode the data, let the\n-                    # user input the password manually.\n                     pass\n             # Allow SIGINT to pass to psql to abort queries.\n             signal.signal(signal.SIGINT, signal.SIG_IGN)\n-            subprocess.check_call(args)\n+            subprocess.run(args, env=env, check=True)\n         finally:\n             # Restore the original SIGINT handler.\n             signal.signal(signal.SIGINT, sigint_handler)\n-            if temp_pgpass:\n-                temp_pgpass.close()\n-                if 'PGPASSFILE' in os.environ:  # unit tests need cleanup\n-                    del os.environ['PGPASSFILE']\n \n     def runshell(self):\n         DatabaseClient.runshell_db(self.connection.get_connection_params())\n"
  },
  "scikit-learn__scikit-learn-26323": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "scikit-learn__scikit-learn-26323",
    "model_patch": "diff --git a/sklearn/compose/_column_transformer.py b/sklearn/compose/_column_transformer.py\nindex 4eddd12b1..915e2d813 100644\n--- a/sklearn/compose/_column_transformer.py\n+++ b/sklearn/compose/_column_transformer.py\n@@ -303,6 +303,20 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n         for trans in transformers:\n             _safe_set_output(trans, transform=transform)\n \n+        # Ensure that the `remainder` estimator (when provided as an estimator)\n+        # also has its output configured. This was previously missed when the\n+        # ColumnTransformer was not yet fitted and hence the remainder was not\n+        # part of `transformers_`.\n+        remainder = getattr(self, \"remainder\", None)\n+        if remainder is not None and remainder not in {\"passthrough\", \"drop\"}:\n+            # _safe_set_output already handles estimators that don't support\n+            # set_output; wrap in try/except to be defensive in case of unexpected objects.\n+            try:\n+                _safe_set_output(remainder, transform=transform)\n+            except Exception:\n+                # Keep current behavior if remainder cannot be configured.\n+                pass\n+\n         return self\n \n     def get_params(self, deep=True):\n"
  },
  "django__django-7530": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-7530",
    "model_patch": "diff --git a/django/core/management/commands/makemigrations.py b/django/core/management/commands/makemigrations.py\nindex 0b39536f5b..e648880ef0 100644\n--- a/django/core/management/commands/makemigrations.py\n+++ b/django/core/management/commands/makemigrations.py\n@@ -105,7 +105,7 @@ class Command(BaseCommand):\n                     # At least one model must be migrated to the database.\n                     router.allow_migrate(connection.alias, app_label, model_name=model._meta.object_name)\n                     for app_label in consistency_check_labels\n-                    for model in apps.get_models(app_label)\n+                    for model in apps.get_app_config(app_label).get_models()\n             )):\n                 loader.check_consistent_history(connection)\n \n"
  },
  "django__django-16662": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-16662",
    "model_patch": "diff --git a/django/db/migrations/writer.py b/django/db/migrations/writer.py\nindex a59f0c8dcb..4d0d1e04c6 100644\n--- a/django/db/migrations/writer.py\n+++ b/django/db/migrations/writer.py\n@@ -175,7 +175,15 @@ class MigrationWriter:\n \n         # Sort imports by the package / module to be imported (the part after\n         # \"from\" in \"from ... import ...\" or after \"import\" in \"import ...\").\n-        sorted_imports = sorted(imports, key=lambda i: i.split()[1])\n+        # For the same package/module, prefer plain \"import <module>\" lines\n+        # before \"from <module> import ...\" lines (matches isort defaults).\n+        sorted_imports = sorted(\n+            imports,\n+            key=lambda i: (\n+                i.split()[1],\n+                0 if i.startswith(\"import \") else 1,\n+            ),\n+        )\n         items[\"imports\"] = \"\\n\".join(sorted_imports) + \"\\n\" if imports else \"\"\n         if migration_imports:\n             items[\"imports\"] += (\n"
  },
  "django__django-14011": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-14011",
    "model_patch": "diff --git a/django/core/servers/basehttp.py b/django/core/servers/basehttp.py\nindex 14dab517c9..d71c4ee63e 100644\n--- a/django/core/servers/basehttp.py\n+++ b/django/core/servers/basehttp.py\n@@ -81,6 +81,28 @@ class ThreadedWSGIServer(socketserver.ThreadingMixIn, WSGIServer):\n     \"\"\"A threaded version of the WSGIServer\"\"\"\n     daemon_threads = True\n \n+    def process_request_thread(self, request, client_address):\n+        \"\"\"Ensure database connections are closed when a request thread\n+        finishes.\n+\n+        ThreadingMixIn.process_request_thread runs the request handler in a\n+        separate thread; when that thread finishes it's important to close any\n+        database connections that were used by that thread so they don't remain\n+        open and block test database teardown.\n+        \"\"\"\n+        try:\n+            return super().process_request_thread(request, client_address)\n+        finally:\n+            # Close all DB connections associated with this thread. Import here to\n+            # avoid importing django.db at module import time.\n+            try:\n+                from django.db import connections\n+                connections.close_all()\n+            except Exception:\n+                # Being defensive: don't let DB errors interfere with request handling.\n+                pass\n+\n+\n \n class ServerHandler(simple_server.ServerHandler):\n     http_version = '1.1'\n"
  },
  "django__django-11179": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-11179",
    "model_patch": "diff --git a/django/db/models/deletion.py b/django/db/models/deletion.py\nindex 92fe4affb9..6111bd9389 100644\n--- a/django/db/models/deletion.py\n+++ b/django/db/models/deletion.py\n@@ -277,6 +277,9 @@ class Collector:\n             if self.can_fast_delete(instance):\n                 with transaction.mark_for_rollback_on_error():\n                     count = sql.DeleteQuery(model).delete_batch([instance.pk], self.using)\n+                # Clear the primary key on the in-memory instance to reflect that\n+                # it has been deleted from the database.\n+                setattr(instance, model._meta.pk.attname, None)\n                 return count, {model._meta.label: count}\n \n         with transaction.atomic(using=self.using, savepoint=False):\n"
  },
  "sympy__sympy-17655": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sympy__sympy-17655",
    "model_patch": "diff --git a/sympy/geometry/point.py b/sympy/geometry/point.py\nindex 7c978c47be..9635a80228 100644\n--- a/sympy/geometry/point.py\n+++ b/sympy/geometry/point.py\n@@ -32,6 +32,7 @@\n from sympy.core.numbers import Float\n from sympy.core.evaluate import global_evaluate\n from sympy.core.add import Add\n+from sympy.core.mul import Mul\n from sympy.utilities.iterables import uniq\n from sympy.utilities.misc import filldedent, func_name, Undecidable\n \n@@ -183,7 +184,7 @@ def __abs__(self):\n         return Point.distance(origin, self)\n \n     def __add__(self, other):\n-        \"\"\"Add other to self by incrementing self's coordinates by\n+        \\\"\\\"\\\"Add other to self by incrementing self's coordinates by\n         those of other.\n \n         Notes\n@@ -212,11 +213,23 @@ def __add__(self, other):\n \n         sympy.geometry.point.Point.translate\n \n-        \"\"\"\n+        \\\"\\\"\\\"\n         try:\n+            # Handle cases where a Mul was produced (e.g., number * Point)\n+            # by converting a Mul containing exactly one Point into a scaled Point.\n+            if isinstance(other, Mul):\n+                # find Point factors inside the Mul\n+                point_args = [a for a in other.args if isinstance(a, Point)]\n+                if len(point_args) == 1:\n+                    pt = point_args[0]\n+                    scalar_args = [a for a in other.args if a is not pt]\n+                    scalar = Mul(*scalar_args) if scalar_args else S.One\n+                    # create a scaled point (uses Point.__mul__)\n+                    other = pt * scalar\n+\n             s, o = Point._normalize_dimension(self, Point(other, evaluate=False))\n         except TypeError:\n-            raise GeometryError(\"Don't know how to add {} and a Point object\".format(other))\n+            raise GeometryError(\\\"Don't know how to add {} and a Point object\\\".format(other))\n \n         coords = [simplify(a + b) for a, b in zip(s, o)]\n         return Point(coords, evaluate=False)\n"
  },
  "django__django-13810": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-13810",
    "model_patch": "diff --git a/django/core/handlers/base.py b/django/core/handlers/base.py\nindex 8e8c3da06a..5af0ab131c 100644\n--- a/django/core/handlers/base.py\n+++ b/django/core/handlers/base.py\n@@ -50,12 +50,15 @@ class BaseHandler:\n             else:\n                 middleware_is_async = middleware_can_async\n             try:\n-                # Adapt handler, if needed.\n-                handler = self.adapt_method_mode(\n+                # Adapt handler, if needed (don't overwrite the outer\n+                # handler until the middleware is constructed). This avoids\n+                # leaving the handler in an adapted state when the\n+                # middleware __init__ raises MiddlewareNotUsed.\n+                adapted_handler = self.adapt_method_mode(\n                     middleware_is_async, handler, handler_is_async,\n                     debug=settings.DEBUG, name='middleware %s' % middleware_path,\n                 )\n-                mw_instance = middleware(handler)\n+                mw_instance = middleware(adapted_handler)\n             except MiddlewareNotUsed as exc:\n                 if settings.DEBUG:\n                     if str(exc):\n"
  },
  "django__django-13297": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-13297",
    "model_patch": "diff --git a/django/views/generic/base.py b/django/views/generic/base.py\nindex ea5baca08d..80b25401f4 100644\n--- a/django/views/generic/base.py\n+++ b/django/views/generic/base.py\n@@ -27,6 +27,29 @@ class ContextMixin:\n         kwargs.setdefault('view', self)\n         if self.extra_context is not None:\n             kwargs.update(self.extra_context)\n+        # Unwrap any SimpleLazyObject values passed via URL kwargs.\n+        # Historically URL kwargs were plain values; as of the deprecation\n+        # wrapper they are provided as SimpleLazyObject instances that emit a\n+        # RemovedInDjango40Warning when accessed. Leaving those proxy objects\n+        # in the context can cause problems when user code expects real values\n+        # (for example, filtering ORM querysets using a slug value). To avoid\n+        # passing proxy objects to callers of get_context_data(), force\n+        # evaluation of SimpleLazyObject instances here.\n+        try:\n+            from django.utils.functional import SimpleLazyObject, empty\n+        except Exception:\n+            SimpleLazyObject = None\n+            empty = None\n+\n+        if SimpleLazyObject is not None:\n+            for key, value in list(kwargs.items()):\n+                if isinstance(value, SimpleLazyObject):\n+                    # Ensure the wrapped object is initialized and store the\n+                    # actual value in the context dictionary.\n+                    if getattr(value, '_wrapped', empty) is empty:\n+                        # Initialize the wrapped object.\n+                        value._setup()\n+                    kwargs[key] = value._wrapped\n         return kwargs\n \n \n"
  },
  "django__django-14053": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-14053",
    "model_patch": "diff --git a/django/contrib/staticfiles/storage.py b/django/contrib/staticfiles/storage.py\nindex 494890cc23..d30ba81cef 100644\n--- a/django/contrib/staticfiles/storage.py\n+++ b/django/contrib/staticfiles/storage.py\n@@ -226,17 +226,43 @@ class HashedFilesMixin:\n             path for path in paths\n             if matches_patterns(path, self._patterns)\n         ]\n+\n+        # Track which original file names have been yielded so we don't yield\n+        # the same original filename multiple times across multiple passes.\n+        yielded = set()\n+\n         # Do a single pass first. Post-process all files once, then repeat for\n-        # adjustable files.\n+        # adjustable files. For adjustable files, we want to avoid yielding them\n+        # during this initial pass to prevent duplicates, but still process them\n+        # so their hashes are known for subsequent passes. Exceptions should be\n+        # yielded immediately so callers can react to errors.\n         for name, hashed_name, processed, _ in self._post_process(paths, adjustable_paths, hashed_files):\n-            yield name, hashed_name, processed\n+            # If an exception occurred during processing, yield it immediately.\n+            if isinstance(processed, Exception):\n+                yield name, hashed_name, processed\n+                yielded.add(name)\n+                continue\n+            # Only yield non-adjustable files on the first pass.\n+            if name not in adjustable_paths:\n+                yield name, hashed_name, processed\n+                yielded.add(name)\n \n+        # Restrict to adjustable files only for subsequent passes.\n         paths = {path: paths[path] for path in adjustable_paths}\n \n         for i in range(self.max_post_process_passes):\n             substitutions = False\n             for name, hashed_name, processed, subst in self._post_process(paths, adjustable_paths, hashed_files):\n-                yield name, hashed_name, processed\n+                # If an exception occurred, yield it (unless already yielded).\n+                if isinstance(processed, Exception):\n+                    if name not in yielded:\n+                        yield name, hashed_name, processed\n+                        yielded.add(name)\n+                else:\n+                    # Only yield a given original filename once.\n+                    if name not in yielded:\n+                        yield name, hashed_name, processed\n+                        yielded.add(name)\n                 substitutions = substitutions or subst\n \n             if not substitutions:\n@@ -247,7 +273,6 @@ class HashedFilesMixin:\n \n         # Store the processed paths\n         self.hashed_files.update(hashed_files)\n-\n     def _post_process(self, paths, adjustable_paths, hashed_files):\n         # Sort the files by directory level\n         def path_level(name):\n"
  },
  "astropy__astropy-7166": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "astropy__astropy-7166",
    "model_patch": ""
  },
  "pytest-dev__pytest-7490": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "pytest-dev__pytest-7490",
    "model_patch": "diff --git a/src/_pytest/skipping.py b/src/_pytest/skipping.py\nindex 335e10996..065049607 100644\n--- a/src/_pytest/skipping.py\n+++ b/src/_pytest/skipping.py\n@@ -262,6 +262,12 @@ def pytest_runtest_makereport(item: Item, call: CallInfo[None]):\n     outcome = yield\n     rep = outcome.get_result()\n     xfailed = item._store.get(xfailed_key, None)\n+    # Re-evaluate xfail marks for the call phase to pick up markers that\n+    # may have been added during test execution (e.g. request.node.add_marker).\n+    # This ensures dynamically applied xfail markers are respected in reporting.\n+    if not item.config.option.runxfail and rep.when == \"call\":\n+        xfailed = evaluate_xfail_marks(item)\n+        item._store[xfailed_key] = xfailed\n     # unittest special case, see setting of unexpectedsuccess_key\n     if unexpectedsuccess_key in item._store and rep.when == \"call\":\n         reason = item._store[unexpectedsuccess_key]\n"
  },
  "psf__requests-1921": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "psf__requests-1921",
    "model_patch": "diff --git a/requests/sessions.py b/requests/sessions.py\nindex a023e4e..637a0dd 100644\n--- a/requests/sessions.py\n+++ b/requests/sessions.py\n@@ -54,8 +54,9 @@ def merge_setting(request_setting, session_setting, dict_class=OrderedDict):\n     merged_setting = dict_class(to_key_val_list(session_setting))\n     merged_setting.update(to_key_val_list(request_setting))\n \n-    # Remove keys that are set to None.\n-    for (k, v) in request_setting.items():\n+    # Remove keys that are set to None in either the request or the session.\n+    # A value of ``None`` is used to signal that a key should not be sent.\n+    for (k, v) in list(merged_setting.items()):\n         if v is None:\n             del merged_setting[k]\n \n"
  },
  "django__django-12406": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-12406",
    "model_patch": "diff --git a/django/db/models/fields/related.py b/django/db/models/fields/related.py\nindex f269d9e17f..479c7695c6 100644\n--- a/django/db/models/fields/related.py\n+++ b/django/db/models/fields/related.py\n@@ -415,6 +415,24 @@ class RelatedField(FieldCacheMixin, Field):\n             defaults.update({\n                 'limit_choices_to': limit_choices_to,\n             })\n+\n+        # If the model field is not blank and the widget is a RadioSelect,\n+        # avoid providing an empty_label to the ModelChoiceField. RadioSelect\n+        # has an inherent unfilled state and showing a \"---------\" choice\n+        # makes that blank option look like a valid choice for required fields.\n+        # Respect an explicit empty_label in kwargs if provided.\n+        widget = kwargs.get('widget')\n+        if widget is None and 'widget' in defaults:\n+            widget = defaults['widget']\n+\n+        if ('empty_label' not in kwargs) and (not self.blank):\n+            try:\n+                from django.forms import RadioSelect\n+            except Exception:\n+                RadioSelect = None\n+            if RadioSelect is not None and isinstance(widget, RadioSelect):\n+                defaults['empty_label'] = None\n+\n         defaults.update(kwargs)\n         return super().formfield(**defaults)\n \n"
  },
  "sphinx-doc__sphinx-9658": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9658",
    "model_patch": "diff --git a/sphinx/util/typing.py b/sphinx/util/typing.py\nindex 87707d48f..fcb7f9d47 100644\n--- a/sphinx/util/typing.py\n+++ b/sphinx/util/typing.py\n@@ -104,6 +104,36 @@ def is_system_TypeVar(typ: Any) -> bool:\n     return modname == 'typing' and isinstance(typ, TypeVar)\n \n \n+\n+def _safe_name(obj: Optional[Type]) -> str:\n+    \"\"\"\n+    Return a safe name for an object to be used in module.name formatting.\n+    Fallback order:\n+      - __qualname__\n+      - __name__\n+      - obj.__class__.__name__\n+      - repr(obj)\n+    This avoids producing texts like \"module.\" when the name is missing (e.g. mocked classes).\n+    \"\"\"\n+    if obj is None:\n+        return ''\n+    name = getattr(obj, '__qualname__', None) or getattr(obj, '__name__', None)\n+    if name:\n+        return name\n+    cls = getattr(obj, '__class__', None)\n+    if cls is not None:\n+        name = getattr(cls, '__name__', None)\n+        if name:\n+            return name\n+    # fallback: try to extract something readable from repr\n+    rep = repr(obj)\n+    # strip common wrappers like \"<class '...'>\"\n+    if rep.startswith(\"<class '\") and rep.endswith(\"'>\"):\n+        inner = rep[len(\"<class '\"):-2]\n+        # return last dotted component\n+        return inner.split('.')[-1]\n+    return rep\n+\n def restify(cls: Optional[Type]) -> str:\n     \"\"\"Convert python class to a reST reference.\"\"\"\n     from sphinx.util import inspect  # lazy loading\n@@ -121,7 +151,7 @@ def restify(cls: Optional[Type]) -> str:\n             if sys.version_info > (3, 10):\n                 # newtypes have correct module info since Python 3.10+\n                 print(cls, type(cls), dir(cls))\n-                return ':py:class:`%s.%s`' % (cls.__module__, cls.__name__)\n+                return ':py:class:`%s.%s`' % (cls.__module__, _safe_name(cls))\n             else:\n                 return ':py:class:`%s`' % cls.__name__\n         elif UnionType and isinstance(cls, UnionType):\n@@ -193,17 +223,17 @@ def _restify_py37(cls: Optional[Type]) -> str:\n         return ':py:obj:`~%s.%s`' % (cls.__module__, cls._name)\n     elif hasattr(cls, '__qualname__'):\n         if cls.__module__ == 'typing':\n-            return ':py:class:`~%s.%s`' % (cls.__module__, cls.__qualname__)\n+            return ':py:class:`~%s.%s`' % (cls.__module__, _safe_name(cls))\n         else:\n-            return ':py:class:`%s.%s`' % (cls.__module__, cls.__qualname__)\n+            return ':py:class:`%s.%s`' % (cls.__module__, _safe_name(cls))\n     elif isinstance(cls, ForwardRef):\n         return ':py:class:`%s`' % cls.__forward_arg__\n     else:\n         # not a class (ex. TypeVar)\n         if cls.__module__ == 'typing':\n-            return ':py:obj:`~%s.%s`' % (cls.__module__, cls.__name__)\n+            return ':py:obj:`~%s.%s`' % (cls.__module__, _safe_name(cls))\n         else:\n-            return ':py:obj:`%s.%s`' % (cls.__module__, cls.__name__)\n+            return ':py:obj:`%s.%s`' % (cls.__module__, _safe_name(cls))\n \n \n def _restify_py36(cls: Optional[Type]) -> str:\n@@ -220,7 +250,7 @@ def _restify_py36(cls: Optional[Type]) -> str:\n         else:\n             qualname = repr(cls).replace('typing.', '')\n     elif hasattr(cls, '__qualname__'):\n-        qualname = '%s.%s' % (module, cls.__qualname__)\n+        qualname = '%s.%s' % (module, _safe_name(cls))\n     else:\n         qualname = repr(cls)\n \n@@ -275,9 +305,9 @@ def _restify_py36(cls: Optional[Type]) -> str:\n             return ':py:obj:`Union`'\n     elif hasattr(cls, '__qualname__'):\n         if cls.__module__ == 'typing':\n-            return ':py:class:`~%s.%s`' % (cls.__module__, cls.__qualname__)\n+            return ':py:class:`~%s.%s`' % (cls.__module__, _safe_name(cls))\n         else:\n-            return ':py:class:`%s.%s`' % (cls.__module__, cls.__qualname__)\n+            return ':py:class:`%s.%s`' % (cls.__module__, _safe_name(cls))\n     elif hasattr(cls, '_name'):\n         # SpecialForm\n         if cls.__module__ == 'typing':\n@@ -287,9 +317,9 @@ def _restify_py36(cls: Optional[Type]) -> str:\n     elif hasattr(cls, '__name__'):\n         # not a class (ex. TypeVar)\n         if cls.__module__ == 'typing':\n-            return ':py:obj:`~%s.%s`' % (cls.__module__, cls.__name__)\n+            return ':py:obj:`~%s.%s`' % (cls.__module__, _safe_name(cls))\n         else:\n-            return ':py:obj:`%s.%s`' % (cls.__module__, cls.__name__)\n+            return ':py:obj:`%s.%s`' % (cls.__module__, _safe_name(cls))\n     else:\n         # others (ex. Any)\n         if cls.__module__ == 'typing':\n@@ -355,7 +385,7 @@ def _stringify_py37(annotation: Any) -> str:\n         else:\n             qualname = stringify(annotation.__origin__)  # ex. Union\n     elif hasattr(annotation, '__qualname__'):\n-        qualname = '%s.%s' % (module, annotation.__qualname__)\n+        qualname = '%s.%s' % (module, _safe_name(annotation))\n     elif hasattr(annotation, '__origin__'):\n         # instantiated generic provided by a user\n         qualname = stringify(annotation.__origin__)\n@@ -420,7 +450,7 @@ def _stringify_py36(annotation: Any) -> str:\n         else:\n             qualname = repr(annotation).replace('typing.', '')\n     elif hasattr(annotation, '__qualname__'):\n-        qualname = '%s.%s' % (module, annotation.__qualname__)\n+        qualname = '%s.%s' % (module, _safe_name(annotation))\n     else:\n         qualname = repr(annotation)\n \n"
  },
  "psf__requests-2931": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "psf__requests-2931",
    "model_patch": "diff --git a/requests/utils.py b/requests/utils.py\nindex 132cd2b..1b04d6d 100644\n--- a/requests/utils.py\n+++ b/requests/utils.py\n@@ -688,19 +688,35 @@ def to_native_string(string, encoding='ascii'):\n     Given a string object, regardless of type, returns a representation of that\n     string in the native string type, encoding and decoding where necessary.\n     This assumes ASCII unless told otherwise.\n-    \"\"\"\n-    out = None\n \n+    Notes:\n+    - If `string` is already a native str (builtin_str), return it unchanged.\n+    - If `string` is bytes on Python 3, attempt to decode using the provided\n+      encoding. If decoding fails (i.e. the bytes are arbitrary/binary data),\n+      return the original bytes unchanged rather than raising. This preserves\n+      binary payloads (e.g. file uploads or explicitly-encoded data) when\n+      callers pass raw bytes.\n+    - On Python 2, attempt to encode unicode to bytes using the provided\n+      encoding. If that fails, return the original value.\n+    \"\"\"\n     if isinstance(string, builtin_str):\n-        out = string\n-    else:\n-        if is_py2:\n-            out = string.encode(encoding)\n-        else:\n-            out = string.decode(encoding)\n-\n-    return out\n+        return string\n \n+    # Attempt to convert/encode/decode, but be tolerant of binary data.\n+    if is_py2:\n+        try:\n+            return string.encode(encoding)\n+        except (UnicodeEncodeError, AttributeError):\n+            # If encoding fails or the object doesn't support .encode,\n+            # return it unchanged.\n+            return string\n+    else:\n+        try:\n+            return string.decode(encoding)\n+        except (UnicodeDecodeError, AttributeError):\n+            # If decoding fails (non-text bytes) or the object isn't bytes,\n+            # return it unchanged so binary payloads are preserved.\n+            return string\n \n def urldefragauth(url):\n     \"\"\"\n"
  },
  "sphinx-doc__sphinx-9230": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9230",
    "model_patch": "diff --git a/sphinx/ext/napoleon/docstring.py b/sphinx/ext/napoleon/docstring.py\nindex d8cb75a5f..fff615925 100644\n--- a/sphinx/ext/napoleon/docstring.py\n+++ b/sphinx/ext/napoleon/docstring.py\n@@ -266,8 +266,22 @@ class GoogleDocstring:\n         if parse_type:\n             match = _google_typed_arg_regex.match(before)\n             if match:\n+                # Standard Google style: \"name(type)\"\n                 _name = match.group(1).strip()\n                 _type = match.group(2)\n+            else:\n+                # Also accept the alternative \"type name\" form commonly used\n+                # in Sphinx/reST param fields, e.g.:\n+                #   \":param dict(str, str) opc_meta: (optional)\"\n+                # In that case, parse out the type (which may contain commas\n+                # and parentheses) and the trailing name.\n+                # We look for a closing parenthesis followed by whitespace and\n+                # then the name. This is a pragmatic heuristic to handle\n+                # complex type specs that appear before the parameter name.\n+                alt_match = re.match(r'(.+\\))\\s+(.+)$', before)\n+                if alt_match:\n+                    _type = alt_match.group(1).strip()\n+                    _name = alt_match.group(2).strip()\n \n         _name = self._escape_args_and_kwargs(_name)\n \n"
  }
}