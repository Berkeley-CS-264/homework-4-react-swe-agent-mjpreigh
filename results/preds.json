{
  "django__django-11179": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-11179",
    "model_patch": "diff --git a/django/db/models/deletion.py b/django/db/models/deletion.py\nindex 92fe4affb9..8743b78b07 100644\n--- a/django/db/models/deletion.py\n+++ b/django/db/models/deletion.py\n@@ -277,6 +277,8 @@ class Collector:\n             if self.can_fast_delete(instance):\n                 with transaction.mark_for_rollback_on_error():\n                     count = sql.DeleteQuery(model).delete_batch([instance.pk], self.using)\n+                # Ensure the in-memory instance reflects the deletion by clearing its PK.\n+                setattr(instance, model._meta.pk.attname, None)\n                 return count, {model._meta.label: count}\n \n         with transaction.atomic(using=self.using, savepoint=False):\n"
  },
  "django__django-14011": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-14011",
    "model_patch": "diff --git a/django/test/testcases.py b/django/test/testcases.py\nindex 92f566b7b0..a483f18e61 100644\n--- a/django/test/testcases.py\n+++ b/django/test/testcases.py\n@@ -1514,11 +1514,22 @@ class LiveServerThread(threading.Thread):\n             connections.close_all()\n \n     def _create_server(self):\n-        return self.server_class(\n+        # Create the server instance. Ensure daemon_threads is False so that\n+        # shutdown() waits for request handler threads to finish. This makes\n+        # sure per-thread resources (like database connections) are closed\n+        # before the live server thread exits, avoiding races on teardown\n+        # (see #22414 regression where test DB couldn't be destroyed).\n+        httpd = self.server_class(\n             (self.host, self.port),\n             QuietWSGIRequestHandler,\n             allow_reuse_address=False,\n         )\n+        # ThreadingMixIn.daemon_threads determines whether the server waits\n+        # for request threads to terminate on shutdown. Set it to False so\n+        # shutdown() blocks until threads have finished and closed DB\n+        # connections.\n+        httpd.daemon_threads = False\n+        return httpd\n \n     def terminate(self):\n         if hasattr(self, 'httpd'):\n"
  },
  "django__django-13297": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-13297",
    "model_patch": "diff --git a/django/views/generic/base.py b/django/views/generic/base.py\nindex ea5baca08d..0d44c9ec79 100644\n--- a/django/views/generic/base.py\n+++ b/django/views/generic/base.py\n@@ -159,8 +159,14 @@ class TemplateView(TemplateResponseMixin, ContextMixin, View):\n     def get(self, request, *args, **kwargs):\n         # RemovedInDjango40Warning: when the deprecation ends, replace with:\n         #   context = self.get_context_data()\n-        context_kwargs = _wrap_url_kwargs_with_deprecation_warning(kwargs)\n-        context = self.get_context_data(**context_kwargs)\n+        # Pass the raw URL kwargs to get_context_data so view code receives real\n+        # values (not SimpleLazyObject), then add lazily-wrapped kwargs into\n+        # the context for templates to trigger the deprecation warning when\n+        # accessed from templates.\n+        context = self.get_context_data(**kwargs)\n+        wrapped = _wrap_url_kwargs_with_deprecation_warning(kwargs)\n+        for key, value in wrapped.items():\n+            context.setdefault(key, value)\n         return self.render_to_response(context)\n \n \n"
  },
  "sympy__sympy-24213": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sympy__sympy-24213",
    "model_patch": "diff --git a/sympy/physics/units/unitsystem.py b/sympy/physics/units/unitsystem.py\nindex a436880c4b..af0bd54337 100644\n--- a/sympy/physics/units/unitsystem.py\n+++ b/sympy/physics/units/unitsystem.py\n@@ -175,7 +175,8 @@ def _collect_factor_and_dimension(self, expr):\n             for addend in expr.args[1:]:\n                 addend_factor, addend_dim = \\\n                     self._collect_factor_and_dimension(addend)\n-                if dim != addend_dim:\n+                dim_sys = self.get_dimension_system()\n+                if not dim_sys.equivalent_dims(dim, addend_dim):\n                     raise ValueError(\n                         'Dimension of \"{}\" is {}, '\n                         'but it should be {}'.format(\n"
  },
  "django__django-12406": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-12406",
    "model_patch": "*** Begin Patch\n*** Update File: django/db/models/fields/related.py\n@@\n     def formfield(self, *, using=None, **kwargs):\n         if isinstance(self.remote_field.model, str):\n             raise ValueError(\"Cannot create form field for %r yet, because \"\n                              \"its related model %r has not been loaded yet\" %\n                              (self.name, self.remote_field.model))\n-        return super().formfield(**{\n-            'form_class': forms.ModelChoiceField,\n-            'queryset': self.remote_field.model._default_manager.using(using),\n-            'to_field_name': self.remote_field.field_name,\n-            **kwargs,\n-        })\n+        # If the model field does not allow blanks and the widget is a\n+        # RadioSelect (either the class or an instance), do not include an\n+        # empty_label by default. Radio widgets have an inherent unfilled\n+        # state and an explicit blank choice looks like a selectable option.\n+        # Do not override an explicit empty_label provided by the caller.\n+        widget = kwargs.get('widget', None)\n+        if 'empty_label' not in kwargs and not self.blank and widget is not None:\n+            is_radio = False\n+            try:\n+                # widget may be a class (subclass of Widget)\n+                is_radio = issubclass(widget, forms.RadioSelect)\n+            except TypeError:\n+                # widget may be an instance\n+                is_radio = isinstance(widget, forms.RadioSelect)\n+            if is_radio:\n+                kwargs['empty_label'] = None\n+\n+        return super().formfield(**{\n+            'form_class': forms.ModelChoiceField,\n+            'queryset': self.remote_field.model._default_manager.using(using),\n+            'to_field_name': self.remote_field.field_name,\n+            **kwargs,\n+        })\n*** End Patch\n\nNo changes detected to generate a patch."
  },
  "django__django-14053": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-14053",
    "model_patch": "diff --git a/django/contrib/staticfiles/storage.py b/django/contrib/staticfiles/storage.py\nindex 494890cc23..80e1a3b7db 100644\n--- a/django/contrib/staticfiles/storage.py\n+++ b/django/contrib/staticfiles/storage.py\n@@ -228,15 +228,25 @@ class HashedFilesMixin:\n         ]\n         # Do a single pass first. Post-process all files once, then repeat for\n         # adjustable files.\n+        # Track which original files we've already yielded to avoid duplicates\n+        yielded = set()\n         for name, hashed_name, processed, _ in self._post_process(paths, adjustable_paths, hashed_files):\n-            yield name, hashed_name, processed\n+            if name not in yielded:\n+                yielded.add(name)\n+                yield name, hashed_name, processed\n \n         paths = {path: paths[path] for path in adjustable_paths}\n \n         for i in range(self.max_post_process_passes):\n             substitutions = False\n             for name, hashed_name, processed, subst in self._post_process(paths, adjustable_paths, hashed_files):\n-                yield name, hashed_name, processed\n+                # Only yield each original file once. Multiple passes may process\n+                # the same file internally (to resolve nested references), but\n+                # collectstatic and subclasses expect each original file to be\n+                # reported only once.\n+                if name not in yielded:\n+                    yielded.add(name)\n+                    yield name, hashed_name, processed\n                 substitutions = substitutions or subst\n \n             if not substitutions:\n"
  },
  "django__django-16662": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-16662",
    "model_patch": "diff --git a/django/db/migrations/writer.py b/django/db/migrations/writer.py\nindex a59f0c8dcb..18b3f7bc20 100644\n--- a/django/db/migrations/writer.py\n+++ b/django/db/migrations/writer.py\n@@ -173,9 +173,17 @@ class MigrationWriter:\n         else:\n             imports.add(\"from django.db import migrations\")\n \n-        # Sort imports by the package / module to be imported (the part after\n-        # \"from\" in \"from ... import ...\" or after \"import\" in \"import ...\").\n-        sorted_imports = sorted(imports, key=lambda i: i.split()[1])\n+        # Put simple \"import module\" statements before \"from module import ...\" statements\n+        # Sort by (is_from, module_name) where is_from is 0 for \"import\" and 1 for \"from\".\n+        # This ensures we follow Django/isort style of placing \"import module\" before\n+        # \"from module import name\" for the same module.\n+        sorted_imports = sorted(\n+            imports,\n+            key=lambda i: (\n+                0 if i.startswith('import ') else 1,\n+                i.split()[1],\n+            ),\n+        )\n         items[\"imports\"] = \"\\n\".join(sorted_imports) + \"\\n\" if imports else \"\"\n         if migration_imports:\n             items[\"imports\"] += (\n"
  },
  "django__django-7530": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-7530",
    "model_patch": "diff --git a/django/core/management/commands/makemigrations.py b/django/core/management/commands/makemigrations.py\nindex 0b39536f5b..e648880ef0 100644\n--- a/django/core/management/commands/makemigrations.py\n+++ b/django/core/management/commands/makemigrations.py\n@@ -105,7 +105,7 @@ class Command(BaseCommand):\n                     # At least one model must be migrated to the database.\n                     router.allow_migrate(connection.alias, app_label, model_name=model._meta.object_name)\n                     for app_label in consistency_check_labels\n-                    for model in apps.get_models(app_label)\n+                    for model in apps.get_app_config(app_label).get_models()\n             )):\n                 loader.check_consistent_history(connection)\n \n"
  },
  "psf__requests-1921": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "psf__requests-1921",
    "model_patch": "diff --git a/requests/sessions.py b/requests/sessions.py\nindex a023e4e..f97cefa 100644\n--- a/requests/sessions.py\n+++ b/requests/sessions.py\n@@ -54,8 +54,10 @@ def merge_setting(request_setting, session_setting, dict_class=OrderedDict):\n     merged_setting = dict_class(to_key_val_list(session_setting))\n     merged_setting.update(to_key_val_list(request_setting))\n \n-    # Remove keys that are set to None.\n-    for (k, v) in request_setting.items():\n+    # Remove keys that are set to None on either the request or the session.\n+    # This allows callers to signal \"remove this setting/header\" by assigning\n+    # None at either level (previously only request-level None removed keys).\n+    for (k, v) in list(merged_setting.items()):\n         if v is None:\n             del merged_setting[k]\n \n"
  },
  "psf__requests-2931": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "psf__requests-2931",
    "model_patch": "diff --git a/requests/models.py b/requests/models.py\nindex 9c624d3..b8c5d9e 100644\n--- a/requests/models.py\n+++ b/requests/models.py\n@@ -80,8 +80,10 @@ class RequestEncodingMixin(object):\n         if parameters are supplied as a dict.\n         \"\"\"\n \n-        if isinstance(data, (str, bytes)):\n+        if isinstance(data, str):\n             return to_native_string(data)\n+        if isinstance(data, bytes):\n+            return data\n         elif hasattr(data, 'read'):\n             return data\n         elif hasattr(data, '__iter__'):\n"
  },
  "scikit-learn__scikit-learn-26323": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "scikit-learn__scikit-learn-26323",
    "model_patch": "diff --git a/sklearn/compose/_column_transformer.py b/sklearn/compose/_column_transformer.py\nindex 4eddd12b1..c833372ca 100644\n--- a/sklearn/compose/_column_transformer.py\n+++ b/sklearn/compose/_column_transformer.py\n@@ -293,16 +293,23 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n             Estimator instance.\n         \"\"\"\n         super().set_output(transform=transform)\n-        transformers = (\n-            trans\n-            for _, trans, _ in chain(\n-                self.transformers, getattr(self, \"transformers_\", [])\n-            )\n-            if trans not in {\"passthrough\", \"drop\"}\n-        )\n-        for trans in transformers:\n+        seen = set()\n+        def _set_if_needed(trans):\n+            if trans in {\"passthrough\", \"drop\"}:\n+                return\n+            tid = id(trans)\n+            if tid in seen:\n+                return\n+            seen.add(tid)\n             _safe_set_output(trans, transform=transform)\n \n+        for _, trans, _ in chain(self.transformers, getattr(self, \"transformers_\", [])):\n+            _set_if_needed(trans)\n+\n+        # Also set output on remainder estimator if it's an estimator\n+        if hasattr(self, \"remainder\") and self.remainder not in {\"passthrough\", \"drop\"}:\n+            _set_if_needed(self.remainder)\n+\n         return self\n \n     def get_params(self, deep=True):\n"
  },
  "sphinx-doc__sphinx-9658": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9658",
    "model_patch": "*** Begin Patch\n*** Update File: doc/conf.py\n@@\n def setup(app):\n@@\n     app.debug = lambda *args, **kwargs: logger.debug(*args, **kwargs)\n+\n+    # Fix for truncated base names for mocked/external bases (e.g. \"torch.nn.\")\n+    # When autodoc runs with mocked imports, base class objects can be mocks or\n+    # partial objects that render to an incomplete dotted name like \"torch.nn.\".\n+    # Sphinx emits the 'autodoc-process-bases' event with the mutable `bases`\n+    # list; here we register a handler to normalize the bases so that the\n+    # \"Bases: ...\" line shows the full dotted name (module + class).\n+    def _fix_autodoc_bases(app, fullname, obj, options, bases):\n+        # bases is a list of objects (types) that will be passed to restify().\n+        # If restify would produce a truncated name like \"pkg.mod.\", try to\n+        # replace the entry with a string \"pkg.mod.ClassName\" constructed from\n+        # available attributes (prefer __module__ and __qualname__). If we can\n+        # not recover a class name, leave it untouched.\n+        fixed = []\n+        for b in bases:\n+            try:\n+                # If it's already a string, keep it\n+                if isinstance(b, str):\n+                    fixed.append(b)\n+                    continue\n+\n+                # Try to get module and qualname/name\n+                mod = getattr(b, '__module__', None)\n+                qual = getattr(b, '__qualname__', None) or getattr(b, '__name__', None)\n+\n+                # Some mocked objects expose a fullname via repr, try to parse it.\n+                if (not qual or qual.endswith('.')) and not isinstance(b, type):\n+                    # fallback: parse repr like \"<class 'torch.nn.modules.module.Module'>\" etc.\n+                    r = repr(b)\n+                    # look for patterns like \"<class 'pkg.mod.Class'>\"\n+                    import re\n+                    m = re.search(r\"<class '([^']+)'>\", r)\n+                    if m:\n+                        fullname_token = m.group(1)\n+                        # split into module and qualname\n+                        if '.' in fullname_token:\n+                            fixed.append(fullname_token)\n+                            continue\n+\n+                if mod and qual:\n+                    # good: produce module + qualname\n+                    fixed.append(mod + '.' + qual)\n+                    continue\n+\n+            except Exception:\n+                # if anything goes wrong, fall back to original base\n+                pass\n+\n+            # default: keep original base\n+            fixed.append(b)\n+\n+        # mutate bases in-place as Sphinx expects\n+        bases[:] = fixed\n+\n+    app.connect('autodoc-process-bases', _fix_autodoc_bases)\n*** End Patch\n*** End Patch\n\nNo changes detected to generate a patch."
  },
  "sympy__sympy-17655": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sympy__sympy-17655",
    "model_patch": "diff --git a/sympy/geometry/point.py b/sympy/geometry/point.py\nindex 7c978c47be..68d0cf9ba8 100644\n--- a/sympy/geometry/point.py\n+++ b/sympy/geometry/point.py\n@@ -216,7 +216,24 @@ def __add__(self, other):\n         try:\n             s, o = Point._normalize_dimension(self, Point(other, evaluate=False))\n         except TypeError:\n-            raise GeometryError(\"Don't know how to add {} and a Point object\".format(other))\n+            # Allow adding a scalar*Point, e.g. Point + 2*Point (which produces a Mul)\n+            # Try to detect a Mul with exactly one Point factor and convert it\n+            # to a Point by multiplying the Point by the scalar factors.\n+            if isinstance(other, Expr) and getattr(other, 'is_Mul', False):\n+                pts = [a for a in other.args if isinstance(a, Point)]\n+                if len(pts) == 1:\n+                    pt = pts[0]\n+                    scalar = sympify(1)\n+                    for a in other.args:\n+                        if a is pt:\n+                            continue\n+                        scalar *= a\n+                    o_point = pt * scalar\n+                    s, o = Point._normalize_dimension(self, Point(o_point, evaluate=False))\n+                else:\n+                    raise GeometryError(\"Don't know how to add {} and a Point object\".format(other))\n+            else:\n+                raise GeometryError(\"Don't know how to add {} and a Point object\".format(other))\n \n         coords = [simplify(a + b) for a, b in zip(s, o)]\n         return Point(coords, evaluate=False)\n"
  },
  "astropy__astropy-7166": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "astropy__astropy-7166",
    "model_patch": "diff --git a/astropy/utils/misc.py b/astropy/utils/misc.py\nindex de3fb01d1..d85610bf2 100644\n--- a/astropy/utils/misc.py\n+++ b/astropy/utils/misc.py\n@@ -528,9 +528,16 @@ class InheritDocstrings(type):\n                 not key.startswith('_'))\n \n         for key, val in dct.items():\n-            if (inspect.isfunction(val) and\n+            # Support not only plain functions but also descriptors such as\n+            # classmethod, staticmethod and property.  For these descriptors\n+            # the object in the class __dict__ is not a function, so\n+            # inspect.isfunction(val) would be False.  We therefore check\n+            # for those common descriptor types as well.  Use getattr to\n+            # safely check whether a docstring is already present.\n+            if ((inspect.isfunction(val) or\n+                 isinstance(val, (classmethod, staticmethod, property))) and\n                 is_public_member(key) and\n-                val.__doc__ is None):\n+                getattr(val, '__doc__', None) is None):\n                 for base in cls.__mro__[1:]:\n                     super_method = getattr(base, key, None)\n                     if super_method is not None:\n"
  },
  "django__django-13810": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-13810",
    "model_patch": "diff --git a/django/core/handlers/base.py b/django/core/handlers/base.py\nindex 8e8c3da06a..3430524071 100644\n--- a/django/core/handlers/base.py\n+++ b/django/core/handlers/base.py\n@@ -50,12 +50,12 @@ class BaseHandler:\n             else:\n                 middleware_is_async = middleware_can_async\n             try:\n-                # Adapt handler, if needed.\n-                handler = self.adapt_method_mode(\n+                # Adapt handler, if needed, for passing into the middleware factory.\n+                adapted_handler = self.adapt_method_mode(\n                     middleware_is_async, handler, handler_is_async,\n                     debug=settings.DEBUG, name='middleware %s' % middleware_path,\n                 )\n-                mw_instance = middleware(handler)\n+                mw_instance = middleware(adapted_handler)\n             except MiddlewareNotUsed as exc:\n                 if settings.DEBUG:\n                     if str(exc):\n"
  },
  "django__django-16631": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-16631",
    "model_patch": "diff --git a/docs/ref/settings.txt b/docs/ref/settings.txt\nindex 41387886c0..28ab400455 100644\n--- a/docs/ref/settings.txt\n+++ b/docs/ref/settings.txt\n@@ -2269,9 +2269,14 @@ Django will refuse to start if :setting:`SECRET_KEY` is not set.\n The secret key is used for:\n \n * All :doc:`sessions </topics/http/sessions>` if you are using\n-  any other session backend than ``django.contrib.sessions.backends.cache``,\n-  or are using the default\n-  :meth:`~django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash()`.\n+  any other session backend than ``django.contrib.sessions.backends.cache``.\n+\n+  Note: the default :meth:`~django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash()`\n+  uses :func:`django.utils.crypto.salted_hmac()` without consulting\n+  :setting:`SECRET_KEY_FALLBACKS`. Rotating ``SECRET_KEY`` will therefore\n+  invalidate session authentication hashes generated by that method and\n+  will log users out even if the old key is present in\n+  :setting:`SECRET_KEY_FALLBACKS`.\n * All :doc:`messages </ref/contrib/messages>` if you are using\n   :class:`~django.contrib.messages.storage.cookie.CookieStorage` or\n   :class:`~django.contrib.messages.storage.fallback.FallbackStorage`.\n@@ -2280,10 +2285,29 @@ The secret key is used for:\n   different key is provided.\n \n When a secret key is no longer set as :setting:`SECRET_KEY` or contained within\n-:setting:`SECRET_KEY_FALLBACKS` all of the above will be invalidated. When\n-rotating your secret key, you should move the old key to\n-:setting:`SECRET_KEY_FALLBACKS` temporarily. Secret keys are not used for\n-passwords of users and key rotation will not affect them.\n+:setting:`SECRET_KEY_FALLBACKS` all of the above will be invalidated.\n+\n+Note that not all code paths consult :setting:`SECRET_KEY_FALLBACKS` automatically.\n+The fallback list is used by the signing utilities that accept fallback keys\n+(for example the :func:`django.core.signing.get_cookie_signer()` /\n+:class:`~django.core.signing.TimestampSigner` which accept ``fallback_keys``),\n+and by code that explicitly iterates over fallback secrets (for example\n+:class:`django.contrib.auth.tokens.PasswordResetTokenGenerator`). However,\n+lower-level helpers such as :func:`django.utils.crypto.salted_hmac()` do not\n+consult :setting:`SECRET_KEY_FALLBACKS`. In particular,\n+:meth:`~django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash()`\n+uses :func:`salted_hmac()` directly and therefore will be invalidated by a\n+``SECRET_KEY`` rotation even if the previous key is present in\n+:setting:`SECRET_KEY_FALLBACKS`.\n+\n+When rotating your secret key, move the old key to\n+:setting:`SECRET_KEY_FALLBACKS` temporarily to support features that check\n+fallback keys (cookie signing, token generators, etc.), and remove old values\n+from :setting:`SECRET_KEY_FALLBACKS` once you are ready to expire the\n+sessions, password reset tokens, and other signed data generated with them.\n+\n+Secret keys are not used for passwords of users and key rotation will not\n+affect them.\n \n .. note::\n \n"
  },
  "sphinx-doc__sphinx-9230": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9230",
    "model_patch": "diff --git a/sphinx/ext/napoleon/docstring.py b/sphinx/ext/napoleon/docstring.py\nindex d8cb75a5f..1e5dd606b 100644\n--- a/sphinx/ext/napoleon/docstring.py\n+++ b/sphinx/ext/napoleon/docstring.py\n@@ -919,9 +919,52 @@ def _recombine_set_tokens(tokens: List[str]) -> List[str]:\n             except IndexError:\n                 break\n \n+            # handle sets {...} and parenthesized groups (...), so that\n+            # commas inside them are not treated as top-level separators.\n             if token == \"{\":\n                 tokens.appendleft(\"{\")\n                 yield \"\".join(takewhile_set(tokens))\n+            elif token == \"(\":\n+                # similar logic to takewhile_set but for parentheses\n+                def takewhile_paren(tokens):\n+                    open_paren = 0\n+                    previous_token = None\n+                    while True:\n+                        try:\n+                            t = tokens.popleft()\n+                        except IndexError:\n+                            break\n+\n+                        if t == \", \":\n+                            previous_token = t\n+                            continue\n+\n+                        if not t.strip():\n+                            continue\n+\n+                        if t in keywords:\n+                            tokens.appendleft(t)\n+                            if previous_token is not None:\n+                                tokens.appendleft(previous_token)\n+                            break\n+\n+                        if previous_token is not None:\n+                            yield previous_token\n+                            previous_token = None\n+\n+                        if t == \"(\":\n+                            open_paren += 1\n+                        elif t == \")\":\n+                            open_paren -= 1\n+\n+                        yield t\n+\n+                        if open_paren == 0:\n+                            break\n+\n+                # push back the '(' we just consumed and recombine the paren group\n+                tokens.appendleft(\"(\")\n+                yield \"\".join(takewhile_paren(tokens))\n             else:\n                 yield token\n \n"
  },
  "pytest-dev__pytest-7490": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "pytest-dev__pytest-7490",
    "model_patch": "diff --git a/src/_pytest/skipping.py b/src/_pytest/skipping.py\nindex 335e10996..bd95cb478 100644\n--- a/src/_pytest/skipping.py\n+++ b/src/_pytest/skipping.py\n@@ -239,9 +239,27 @@ def pytest_runtest_setup(item: Item) -> None:\n         skip(skipped.reason)\n \n     if not item.config.option.runxfail:\n-        item._store[xfailed_key] = xfailed = evaluate_xfail_marks(item)\n+        # Evaluate xfail marks here only to determine if the test should be\n+        # prevented from running (run=False). For run=True xfails we avoid\n+        # caching the evaluation in setup so that markers added dynamically\n+        # during the test execution (e.g. via request.node.add_marker) are\n+        # picked up later in the call/report phase (see pytest_runtest_call).\n+        xfailed = evaluate_xfail_marks(item)\n         if xfailed and not xfailed.run:\n+            # Store the xfail evaluation and skip the test execution.\n+            item._store[xfailed_key] = xfailed\n             xfail(\"[NOTRUN] \" + xfailed.reason)\n+        else:\n+            # Do not cache run=True xfail evaluations here: leave the store\n+            # without an entry so pytest_runtest_call can evaluate marks\n+            # again and pick up any markers added during test execution.\n+            try:\n+                # Ensure the key is absent; Store-like objects support pop.\n+                item._store.pop(xfailed_key, None)  # type: ignore[attr-defined]\n+            except Exception:\n+                # In case the store doesn't support pop, delete if present.\n+                if xfailed_key in item._store:\n+                    del item._store[xfailed_key]\n \n \n @hookimpl(hookwrapper=True)\n"
  },
  "sphinx-doc__sphinx-7590": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-7590",
    "model_patch": "*** Begin Patch\n*** Update File: sphinx/domains/cpp.py\n@@\n class ASTStringLiteral(ASTLiteral):\n     def __init__(self, data: str) -> None:\n         self.data = data\n@@\n \n     def describe_signature(self, signode: TextElement, mode: str,\n                            env: \"BuildEnvironment\", symbol: \"Symbol\") -> None:\n         txt = str(self)\n         signode.append(nodes.Text(txt, txt))\n \n \n class ASTCharLiteral(ASTLiteral):\n@@\n     def describe_signature(self, signode: TextElement, mode: str,\n                            env: \"BuildEnvironment\", symbol: \"Symbol\") -> None:\n         txt = str(self)\n         signode.append(nodes.Text(txt, txt))\n \n \n+class ASTUserDefinedLiteral(ASTLiteral):\n+    \"\"\"A user-defined-literal: a literal followed immediately by an identifier suffix.\"\"\"\n+    def __init__(self, literal: ASTLiteral, identifier: ASTIdentifier) -> None:\n+        self.literal = literal\n+        self.identifier = identifier\n+\n+    def _stringify(self, transform: StringifyTransform) -> str:\n+        return transform(self.literal) + transform(self.identifier)\n+\n+    def get_id(self, version: int) -> str:\n+        # Compose ids of underlying literal and identifier.\n+        # For older versions where literal id may not be available, fall back to str().\n+        try:\n+            lit_id = self.literal.get_id(version)\n+        except Exception:\n+            lit_id = str(self.literal)\n+        try:\n+            ident_id = self.identifier.get_id(version)\n+        except Exception:\n+            ident_id = str(self.identifier)\n+        return lit_id + ident_id\n+\n+    def describe_signature(self, signode: TextElement, mode: str,\n+                           env: \"BuildEnvironment\", symbol: \"Symbol\") -> None:\n+        verify_description_mode(mode)\n+        # Render literal and suffix together\n+        self.literal.describe_signature(signode, mode, env, symbol)\n+        # suffix is just appended as text (no whitespace)\n+        signode.append(nodes.Text(str(self.identifier)))\n+\n*** End Patch\n\nNo changes detected to generate a patch."
  },
  "django__django-10973": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-10973",
    "model_patch": "diff --git a/django/db/backends/postgresql/client.py b/django/db/backends/postgresql/client.py\nindex 7fca6eff30..458887b543 100644\n--- a/django/db/backends/postgresql/client.py\n+++ b/django/db/backends/postgresql/client.py\n@@ -2,17 +2,9 @@ import os\n import signal\n import subprocess\n \n-from django.core.files.temp import NamedTemporaryFile\n from django.db.backends.base.client import BaseDatabaseClient\n \n \n-def _escape_pgpass(txt):\n-    \"\"\"\n-    Escape a fragment of a PostgreSQL .pgpass file.\n-    \"\"\"\n-    return txt.replace('\\\\', '\\\\\\\\').replace(':', '\\\\:')\n-\n-\n class DatabaseClient(BaseDatabaseClient):\n     executable_name = 'psql'\n \n@@ -34,38 +26,22 @@ class DatabaseClient(BaseDatabaseClient):\n             args += ['-p', str(port)]\n         args += [dbname]\n \n-        temp_pgpass = None\n         sigint_handler = signal.getsignal(signal.SIGINT)\n         try:\n+            env = None\n             if passwd:\n-                # Create temporary .pgpass file.\n-                temp_pgpass = NamedTemporaryFile(mode='w+')\n-                try:\n-                    print(\n-                        _escape_pgpass(host) or '*',\n-                        str(port) or '*',\n-                        _escape_pgpass(dbname) or '*',\n-                        _escape_pgpass(user) or '*',\n-                        _escape_pgpass(passwd),\n-                        file=temp_pgpass,\n-                        sep=':',\n-                        flush=True,\n-                    )\n-                    os.environ['PGPASSFILE'] = temp_pgpass.name\n-                except UnicodeEncodeError:\n-                    # If the current locale can't encode the data, let the\n-                    # user input the password manually.\n-                    pass\n+                # Pass the password via the PGPASSWORD environment variable.\n+                env = os.environ.copy()\n+                env['PGPASSWORD'] = passwd\n             # Allow SIGINT to pass to psql to abort queries.\n             signal.signal(signal.SIGINT, signal.SIG_IGN)\n-            subprocess.check_call(args)\n+            if env is not None:\n+                subprocess.run(args, env=env, check=True)\n+            else:\n+                subprocess.run(args, check=True)\n         finally:\n             # Restore the original SIGINT handler.\n             signal.signal(signal.SIGINT, sigint_handler)\n-            if temp_pgpass:\n-                temp_pgpass.close()\n-                if 'PGPASSFILE' in os.environ:  # unit tests need cleanup\n-                    del os.environ['PGPASSFILE']\n \n     def runshell(self):\n         DatabaseClient.runshell_db(self.connection.get_connection_params())\ndiff --git a/tests/dbshell/test_postgresql.py b/tests/dbshell/test_postgresql.py\nindex 0d4f28554d..6bde6b5eb4 100644\n--- a/tests/dbshell/test_postgresql.py\n+++ b/tests/dbshell/test_postgresql.py\n@@ -11,21 +11,25 @@ class PostgreSqlDbshellCommandTestCase(SimpleTestCase):\n     def _run_it(self, dbinfo):\n         \"\"\"\n         That function invokes the runshell command, while mocking\n-        subprocess.call. It returns a 2-tuple with:\n+        subprocess.run. It returns a 2-tuple with:\n         - The command line list\n-        - The content of the file pointed by environment PGPASSFILE, or None.\n+        - The PGPASSWORD value passed in the subprocess environment, or None.\n         \"\"\"\n-        def _mock_subprocess_call(*args):\n-            self.subprocess_args = list(*args)\n-            if 'PGPASSFILE' in os.environ:\n-                with open(os.environ['PGPASSFILE']) as f:\n-                    self.pgpass = f.read().strip()  # ignore line endings\n+        def _mock_subprocess_run(*args, **kwargs):\n+            # args[0] is the command list\n+            self.subprocess_args = list(args[0])\n+            env = kwargs.get('env')\n+            if env is not None and 'PGPASSWORD' in env:\n+                self.pgpass = env['PGPASSWORD']\n             else:\n                 self.pgpass = None\n-            return 0\n+            class Result:\n+                returncode = 0\n+            return Result()\n+\n         self.subprocess_args = None\n         self.pgpass = None\n-        with mock.patch('subprocess.call', new=_mock_subprocess_call):\n+        with mock.patch('subprocess.run', new=_mock_subprocess_run):\n             DatabaseClient.runshell_db(dbinfo)\n         return self.subprocess_args, self.pgpass\n \n@@ -39,7 +43,7 @@ class PostgreSqlDbshellCommandTestCase(SimpleTestCase):\n                 'port': '444',\n             }), (\n                 ['psql', '-U', 'someuser', '-h', 'somehost', '-p', '444', 'dbname'],\n-                'somehost:444:dbname:someuser:somepassword',\n+                'somepassword',\n             )\n         )\n \n@@ -66,7 +70,7 @@ class PostgreSqlDbshellCommandTestCase(SimpleTestCase):\n                 'port': '444',\n             }), (\n                 ['psql', '-U', 'some:user', '-h', '::1', '-p', '444', 'dbname'],\n-                '\\\\:\\\\:1:444:dbname:some\\\\:user:some\\\\:password',\n+                'some:password',\n             )\n         )\n \n@@ -80,14 +84,13 @@ class PostgreSqlDbshellCommandTestCase(SimpleTestCase):\n                 'port': '444',\n             }), (\n                 ['psql', '-U', 'some\\\\user', '-h', 'somehost', '-p', '444', 'dbname'],\n-                'somehost:444:dbname:some\\\\\\\\user:some\\\\\\\\password',\n+                'some\\\\password',\n             )\n         )\n \n     def test_accent(self):\n         username = 'r\u00f4le'\n         password = 's\u00e9same'\n-        pgpass_string = 'somehost:444:dbname:%s:%s' % (username, password)\n         self.assertEqual(\n             self._run_it({\n                 'database': 'dbname',\n@@ -97,20 +100,23 @@ class PostgreSqlDbshellCommandTestCase(SimpleTestCase):\n                 'port': '444',\n             }), (\n                 ['psql', '-U', username, '-h', 'somehost', '-p', '444', 'dbname'],\n-                pgpass_string,\n+                password,\n             )\n         )\n \n     def test_sigint_handler(self):\n         \"\"\"SIGINT is ignored in Python and passed to psql to abort quries.\"\"\"\n-        def _mock_subprocess_call(*args):\n+        def _mock_subprocess_run(*args, **kwargs):\n             handler = signal.getsignal(signal.SIGINT)\n             self.assertEqual(handler, signal.SIG_IGN)\n+            class Result:\n+                returncode = 0\n+            return Result()\n \n         sigint_handler = signal.getsignal(signal.SIGINT)\n         # The default handler isn't SIG_IGN.\n         self.assertNotEqual(sigint_handler, signal.SIG_IGN)\n-        with mock.patch('subprocess.check_call', new=_mock_subprocess_call):\n+        with mock.patch('subprocess.run', new=_mock_subprocess_run):\n             DatabaseClient.runshell_db({})\n         # dbshell restores the original handler.\n         self.assertEqual(sigint_handler, signal.getsignal(signal.SIGINT))\n"
  }
}